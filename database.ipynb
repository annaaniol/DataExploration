{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "data_sufix = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure Session class with desired options\n",
    "Session = sessionmaker()\n",
    "engine = create_engine('sqlite:///twitter.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = ['h1b', 'usvisa', 'illegalImmigration', 'immigration',\n",
    "'immigrantcaravan', 'caravaninvasion', 'buildthewall', 'illegalaliens']\n",
    "hashtagsDict = {'name': hashtags}\n",
    "unbalancedHashtags = ['birthrightcitizenship', 'immigrationreform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagData = pd.DataFrame.from_dict(hashtagsDict)\n",
    "hashtagData.to_sql('hashtag', engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dates = ['2018-10-27','2018-10-28','2018-10-29','2018-10-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hashtag in hashtags:\n",
    "    \n",
    "    hashtag_id = pd.read_sql_query('SELECT id FROM hashtag WHERE hashtag.name=\"'+hashtag+'\"', engine).values[0][0]\n",
    "\n",
    "    tweetData = pd.read_csv(data_sufix+hashtag+'-tweet.csv', \n",
    "                            usecols=['tweet_id','tweet_text','tweet_created_at','tweet_retweet_count',\n",
    "                                     'tweet_favorite_count','user_id'])\n",
    "    tweetData['hashtag_id'] = hashtag_id\n",
    "    \n",
    "    retweetData = pd.read_csv(data_sufix+hashtag+'-retweet.csv', \n",
    "                              usecols=['retweet_id','source_tweet_id','retweet_text','retweet_created_at','user_id'])\n",
    "    \n",
    "    tweetData = tweetData.loc[tweetData['tweet_created_at'].str.contains('|'.join(valid_dates))]\n",
    "    retweetData = retweetData.loc[retweetData['retweet_created_at'].str.contains('|'.join(valid_dates))]\n",
    "    \n",
    "    tweetData.to_sql('tweet', engine, if_exists='append')\n",
    "    retweetData.to_sql('retweet', engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "userData = pd.read_csv(data_sufix+'user.csv', \n",
    "                        usecols=['user_id','user_name','user_location','user_friends_count','followers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tweeting_user_ids = pd.read_sql_query('SELECT DISTINCT user_id FROM tweet', engine)\n",
    "valid_retweeting_user_ids = pd.read_sql_query('SELECT DISTINCT user_id FROM retweet', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user_ids = valid_tweeting_user_ids['user_id'].tolist() + valid_retweeting_user_ids['user_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44128"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "userData = userData.loc[userData['user_id'].isin(valid_user_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "userData.to_sql('user', engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets (17596, 2)\n",
      "retweets (79436, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056095192930025472</td>\n",
       "      <td>b'@Earlybird0073 @immivoice I guess #h1b #h4ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056125697482256384</td>\n",
       "      <td>b'@AmerMedicalAssn @USCIS #kansas #traitor @Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056125759851556864</td>\n",
       "      <td>b'@AmerMedicalAssn @USCIS @KevinYoder sneaked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056125800196595712</td>\n",
       "      <td>b'@AmerMedicalAssn @USCIS #HR392 has been snea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056125844966592512</td>\n",
       "      <td>b'@AmerMedicalAssn @USCIS 150 year #Backlog of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text\n",
       "0  1056095192930025472  b'@Earlybird0073 @immivoice I guess #h1b #h4ea...\n",
       "1  1056125697482256384  b'@AmerMedicalAssn @USCIS #kansas #traitor @Ke...\n",
       "2  1056125759851556864  b'@AmerMedicalAssn @USCIS @KevinYoder sneaked ...\n",
       "3  1056125800196595712  b'@AmerMedicalAssn @USCIS #HR392 has been snea...\n",
       "4  1056125844966592512  b'@AmerMedicalAssn @USCIS 150 year #Backlog of..."
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HASHTAGS\n",
    "\n",
    "allTweets = pd.read_sql_query('SELECT tweet_id as id, tweet_text as text FROM tweet', engine)\n",
    "print(\"tweets \" + str(allTweets.shape))\n",
    "allRetweets =  pd.read_sql_query('SELECT retweet_id as id, retweet_text as text FROM retweet', engine)\n",
    "print(\"retweets \" + str(allRetweets.shape))\n",
    "textData = allTweets.append([allRetweets])\n",
    "textData.drop_duplicates(inplace=True)\n",
    "textData[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hashes=''\n",
    "regex = r\"#([a-zA-Z\\d]*)\"\n",
    "for index, row in textData.iterrows():\n",
    "    match = re.findall(regex, row[\"text\"])\n",
    "    hashes = list(set(hashes)) + [x.lower() for x in match]\n",
    "# print(hashes)\n",
    "len(hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allHashes = pd.DataFrame({'hashtag':hashes})\n",
    "allHashes.to_sql('hashes', engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDBHashes = pd.read_sql_query('SELECT * FROM hashes', engine)\n",
    "print(allDBHashes.shape)\n",
    "allDBHashes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hashes=''\n",
    "regex = r\"#([a-zA-Z\\d]*)\"\n",
    "tweetToHashes = pd.DataFrame(columns=['tweet_id', 'hash_id'])\n",
    "for index, row in textData.iterrows():\n",
    "    match = re.findall(regex, row[\"text\"])\n",
    "    hashes = [x.lower() for x in match]\n",
    "    tweetID = row[\"id\"]\n",
    "    for hsh in hashes:\n",
    "        hashID = allDBHashes[allDBHashes['hashtag'] == hsh].iloc[0][\"index\"]\n",
    "        tweetToHashes.loc[len(tweetToHashes)]=[tweetID, int(hashID)]\n",
    "tweetToHashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetToHashes.to_sql('tweetToHashes', engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate it with our custom Session class\n",
    "Session.configure(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
